# -*- coding: utf-8 -*-
"""
Created on Fri Jul 18 14:15:48 2025

@author: r_rsq
"""

import spacy
from spacy.training import Example
import pandas as pd
import random
import os
from tqdm import tqdm

# -------------------- CONFIGURACIÃ“N --------------------
BASE_PATH = r'C:\Users\r_rsq\Documents\001_AI_Facturas\Extractor_AI'
DATA_PATH = os.path.join(BASE_PATH, 'data')
MODEL_PATH = os.path.join(BASE_PATH, 'model', 'IRPF')  # Ruta del modelo IRPF
archivo_entrenamiento = os.path.join(DATA_PATH, 'TrainingSet_IRPF.xlsx')

entrenar_desde_cero = True  # True = nuevo modelo desde cero

# -------------------- CARGA DATOS ENTRENAMIENTO --------------------
print("ğŸ“¥ Cargando datos de entrenamiento IRPF...")
df = pd.read_excel(archivo_entrenamiento)
df = df.dropna(subset=['start', 'end'])

train_data = []
for _, row in df.iterrows():
    texto = str(row['texto_extraido'])
    start = int(row['start'])
    end = int(row['end'])
    entidad = row.get('entidad', 'IRPF')  # Default a IRPF
    train_data.append((texto, {'entities': [(start, end, entidad)]}))

print(f"âœ… Datos cargados: {len(train_data)} muestras para entrenar la entidad IRPF.")

# -------------------- PREPARAR MODELO --------------------
if entrenar_desde_cero:
    print("ğŸ§ª Entrenamiento desde cero...")
    nlp = spacy.blank('es')
    ner = nlp.add_pipe('ner')
    for _, annotations in train_data:
        for ent in annotations.get('entities'):
            ner.add_label(ent[2])
else:
    print("ğŸ§  Cargando modelo anterior para continuar entrenamiento...")
    nlp = spacy.load(MODEL_PATH)
    ner = nlp.get_pipe('ner')

# -------------------- ENTRENAMIENTO --------------------
optimizer = nlp.initialize() if entrenar_desde_cero else nlp.resume_training()

print(f"\nğŸš€ Iniciando entrenamiento con {len(train_data)} muestras...")

for itn in tqdm(range(10), desc="ğŸ” Iteraciones", ncols=100):
    random.shuffle(train_data)
    losses = {}

    for text, annotations in tqdm(train_data, desc=f"ğŸ§  Iter {itn+1}", leave=False, ncols=100):
        doc = nlp.make_doc(text)
        example = Example.from_dict(doc, annotations)
        nlp.update([example], drop=0.3, losses=losses)

    tqdm.write(f"ğŸ“‰ PÃ©rdidas en iteraciÃ³n {itn+1}: {losses}")

# -------------------- GUARDAR MODELO --------------------
nlp.to_disk(MODEL_PATH)
print("\nâœ… Modelo IRPF guardado en:", MODEL_PATH)
